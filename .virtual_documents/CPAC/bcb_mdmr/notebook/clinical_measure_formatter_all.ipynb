import pandas as pd

id_table = pd.read_excel("./data/id_table.xlsx")

demographics = pd.read_excel("./data/demographics.xlsx", skiprows=1, header=0)

scores_xls = pd.ExcelFile("./data/scores_new.xlsx")

# Define the function to generate fmri codes
def generate_fmri_code_demo(row):
    prefix = 's' if row['참여집단'] == 'EXP' else 'c'
    return f"{prefix}{int(row['내부 부여 번호']):04d}"


def generate_fmri_code_id_table(row):
    prefix = 's' if row['Enrollment #'].startswith('EXP') else 'c'
    code = f"{prefix}{int(row['Subject #']):04d}"
    return code


# Apply the function to each row
demographics['fmri_code'] = demographics.apply(generate_fmri_code_demo, axis=1)
id_table['fmri_code'] = id_table.apply(generate_fmri_code_id_table, axis=1)

# Merge the two DataFrames on fmri_code
merged_df = pd.merge(demographics, id_table, on=['fmri_code'], how='left')

# Drop rows where fmri_code is NaN
filtered_df = merged_df.dropna(subset=['fmri_code'])

# Convert 'HAID ID' to string for consistent merging
filtered_df['HAID ID'] = filtered_df['HAID ID'].astype(str)

# STAI-X-1
STAI_X_1 = scores_xls.parse("STAI_X_1")

# STAI-X-2
STAI_X_2 = scores_xls.parse("STAI_X_2")

# HADS_anxiety, HADS_depression
HADS = scores_xls.parse("HADS")

# SWLS
SWLS = scores_xls.parse("SWLS")

# GAD_7
GAD_7 = scores_xls.parse("GAD_7")

# PDSS
PDSS = scores_xls.parse("PDSS")

# performance_lsas, social_interaction_lsas, lsas
LSAS = scores_xls.parse("LSAS")

# MOCI, checking, cleaning, doubting, slowness
MOCI = scores_xls.parse("MOCI")

# BFNE
BFNE = scores_xls.parse("BFNE")

# PSWQ
PSWQ = scores_xls.parse("PSWQ")

# FCV_19S
FCV_19S = scores_xls.parse("FCV_19S")

# Handedness(true)
HANDEDNESS = scores_xls.parse("HANDEDNESS")

# Get unique ids from id_lookup_table
lookup_unique_ids = set(id_table['HAID ID'].astype(str).unique())
print(f"Unique ID count in id_lookup_table: {len(lookup_unique_ids)}")

# Function to get unique ids from a sheet
def get_unique_ids(sheet):
    return set(sheet['id'].astype(str).unique())

# List of score sheets
score_sheets = [
    ('STAI_X_1', STAI_X_1),
    ('STAI_X_2', STAI_X_2),
    ('HADS_anxiety', HADS),
    ('HADS_depression', HADS),
    ('SWLS', SWLS),
    ('GAD_7', GAD_7),
    ('PDSS', PDSS),
    ('performance_lsas', LSAS),
    ('social_interaction_lsas', LSAS),
    ('lsas', LSAS),
    ('MOCI', MOCI),
    ('checking', MOCI),
    ('cleaning', MOCI),
    ('doubting', MOCI),
    ('slowness', MOCI),
    ('BFNE', BFNE),
    ('PSWQ', PSWQ),
    ('Handedness(true)', HANDEDNESS),
    ('FCV_19S', FCV_19S)
]

# Check each sheet for unique ids and matches with id_lookup_table
for sheet_name, sheet in score_sheets:
    sheet_unique_ids = get_unique_ids(sheet)
    common_ids = sheet_unique_ids.intersection(lookup_unique_ids)
    print(f"\nSheet: {sheet_name}")
    print(f"Unique ID count in sheet: {len(sheet_unique_ids)}")
    print(f"Common ID count with id_lookup_table: {len(common_ids)}")



demographics.columns



# Convert 'HAID ID' to string for consistent merging
filtered_df['HAID ID'] = filtered_df['HAID ID'].astype(str)





# Assuming filtered_df is already defined and the dataframes for each sheet are already loaded

# Define a function to extract scores
def extract_scores(df, columns, id):
    extracted_col = df[(df['id'] == id) & (df['round'] == 1)][columns]
    if len(extracted_col.values) == 0:
        return "n/a"
    else:
        return extracted_col.values[0][0]

# Dictionary to hold the extracted scores for each id
extracted_scores = []

# Loop through each unique HAID ID and extract the scores for each sheet
for id in filtered_df['HAID ID'].unique():
    target_filtered_df = filtered_df[filtered_df['HAID ID'] == id]
    score_dict = {
        'HAID ID': id,
        'GROUP': target_filtered_df['참여집단'].values[0],
        'Exp No.': target_filtered_df['내부 부여 번호'].values[0],
        '1. SEX': target_filtered_df['성별'].values[0],
        '2.AGE': target_filtered_df['만 나이'].values[0],
        '3-2. YR_EDU': target_filtered_df['교육 기간'].values[0],
        'fmri_code': target_filtered_df['fmri_code'].values[0],
        'Screening #': target_filtered_df['Screening #'].values[0],
        'Enrollment #': target_filtered_df['Enrollment #'].values[0],

        
        'STAI-X-1': extract_scores(STAI_X_1, ['STAI-X-1'], id),
        'STAI-X-2': extract_scores(STAI_X_2, ['STAI-X-2'], id),
        'HADS_anxiety': extract_scores(HADS, ['HADS_anxiety'], id),
        'HADS_depression': extract_scores(HADS, ['HADS_depression'], id),
        'SWLS': extract_scores(SWLS, ['SWLS'], id),
        'GAD-7': extract_scores(GAD_7, ['GAD-7'], id),
        'PDSS': extract_scores(PDSS, ['PDSS'], id),
        'LSAS_performance': extract_scores(LSAS, ['performance_lsas'], id),
        'LSAS_social_interaction': extract_scores(LSAS, ['social_interaction_lsas'], id),
        'LSAS': extract_scores(LSAS, ['lsas'], id),
        'MOCI': extract_scores(MOCI, ['MOCI'], id),
        'MOCI_checking': extract_scores(MOCI, ['checking'], id),
        'MOCI_cleaning': extract_scores(MOCI, ['cleaning'], id),
        'MOCI_doubting': extract_scores(MOCI, ['doubting'], id),
        'MOCI_slowness': extract_scores(MOCI, ['slowness'], id),
        'BFNE': extract_scores(BFNE, ['BFNE'], id),
        'PSWQ': extract_scores(PSWQ, ['PSWQ'], id),
        #'Handedness(true)': extract_scores(HANDEDNESS, ['Handedness(true)'], id),
        'FCV-19S': extract_scores(FCV_19S, ['FCV-19S'], id)
    }
    extracted_scores.append(score_dict)


extracted_scores_df = pd.DataFrame(extracted_scores)


extracted_scores_df


extracted_scores_df.to_csv("./data/participant_demo_clinical_all_new.csv")






